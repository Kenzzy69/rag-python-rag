# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TEMPERATURE=0.7

# Embedding Model
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Storage Paths
CHROMA_PERSIST_DIR=./chroma_db
DOCUMENTS_DIR=./documents
PROCESSED_DOCS_DIR=./processed_docs

# Text Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Retrieval Settings
DEFAULT_N_RESULTS=5

# Gradio Interface
GRADIO_SERVER_PORT=7860
GRADIO_SERVER_NAME=0.0.0.0
GRADIO_SHARE=False

# Logging
LOG_LEVEL=INFO

# Optional: Remote Ollama Instance
# OLLAMA_HOST=http://your-server:11434

# Optional: Alternative Models
# OLLAMA_MODEL=mistral
# OLLAMA_MODEL=llama3.2:1b
# EMBEDDING_MODEL=paraphrase-multilingual-MiniLM-L12-v2
